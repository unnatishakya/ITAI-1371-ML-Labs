{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTs7-hu1lMW1"
      },
      "source": [
        "# Module 05 Lab - Data Preparation\n",
        "\n",
        "**Objective:**\n",
        "\n",
        "To learn and apply the most common data preparation techniques. Raw data is rarely ready for a machine learning model. This process, also called preprocessing, is one of the most critical steps in the entire ML workflow.\n",
        "\n",
        "**In this lab, you will write more of the code.**\n",
        "\n",
        "Read the explanations and then complete the tasks in the code cells."
      ],
      "id": "cTs7-hu1lMW1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qtJ1w7hlMW3"
      },
      "source": [
        "## Part 1: Setup and Initial Look\n",
        "\n",
        "We will continue using the Titanic dataset because it has the exact problems we need to solve: missing values and non-numeric data."
      ],
      "id": "4qtJ1w7hlMW3"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-q9ooDHlMW3",
        "outputId": "e2016e05-6612-413c-9959-b046545f5c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
        "\n",
        "# Let's look at the missing valuesprint(\"--- Missing Values Before Cleaning ---\")\n",
        "print(df.isnull().sum())"
      ],
      "id": "O-q9ooDHlMW3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1NfBFPslMW4"
      },
      "source": [
        "## Part 2: Handling Missing Values (Imputation)\n",
        "\n",
        "**Concept:**\n",
        "\n",
        "Most machine learning models cannot handle missing values (`NaN`). We must deal with them. Dropping the rows is an option, but you lose data. A better way is\n",
        "**imputation**, which means filling in the missing values with a calculated guess.\n",
        "\n",
        "Common imputation strategies:\n",
        "\n",
        "*   **Mean:** Fill with the average value. Good for normally distributed data.\n",
        "*   **Median:** Fill with the middle value. Better for skewed data or data with outliers (like `Fare`).\n",
        "*   **Mode:** Fill with the most frequent value. Used for categorical data."
      ],
      "id": "b1NfBFPslMW4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQDp9mPrlMW4"
      },
      "source": [
        "### Task 1: Impute the 'Age' Column\n",
        "\n",
        "The 'Age' column is missing many values. Since age can be skewed (e.g., by a few very old passengers), using the **median** is a robust choice.\n",
        "\n",
        "**Your Task:** Calculate the median of the 'Age' column and use the `.fillna()` method to replace the missing values."
      ],
      "id": "CQDp9mPrlMW4"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XZODKfnYlMW4"
      },
      "outputs": [],
      "source": [
        "# 1. Calculate the median of the 'Age' column\n",
        "# 2. Fill the missing values in 'Age' with the median\n",
        "# 3. Verify that there are no more missing values in 'Age'\n",
        "#print(\"Missing values in 'Age' after imputation:\")\n",
        "#print(df['Age'].isnull().sum())"
      ],
      "id": "XZODKfnYlMW4"
    },
    {
      "cell_type": "code",
      "source": [
        "df['Age'].median()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQpuKoMavMW6",
        "outputId": "34e83ca3-f97f-404f-d9bc-37c2ceb1f211"
      },
      "id": "JQpuKoMavMW6",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_mediumage = df['Age'].median()"
      ],
      "metadata": {
        "id": "AUscTFNZvWE2"
      },
      "id": "AUscTFNZvWE2",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Age'] = df['Age'].fillna(df_mediumage)"
      ],
      "metadata": {
        "id": "EhQuid5Hvils"
      },
      "id": "EhQuid5Hvils",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in 'Age' after imputation:\")\n",
        "print(df['Age'].isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhQMP21XvpVf",
        "outputId": "116f3672-58a7-428c-fd78-5abbb6b0a2f2"
      },
      "id": "JhQMP21XvpVf",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in 'Age' after imputation:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV9RYWP_lMW5"
      },
      "source": [
        "## Part 3: Encoding Categorical Features\n",
        "\n",
        "**Concept:** Machine learning models are mathematical, so they need numbers, not text. We need to convert categorical columns (like 'Sex' and 'Embarked') into a numerical format. The most common method is\n",
        "\n",
        "**One-Hot Encoding**.One-Hot Encoding takes a column with `N` categories and turns it into `N` new columns, each with a `1` or `0`. For example, the 'Sex' column (`male`, `female`) becomes two new columns: `Sex_male` and `Sex_female`.Pandas has a convenient function called `pd.get_dummies()` that does this for us."
      ],
      "id": "IV9RYWP_lMW5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax-Io0aBlMW5"
      },
      "source": [
        "### Task 2: One-Hot Encode Categorical Columns\n",
        "\n",
        "**Your Task:** Use `pd.get_dummies()` to encode the 'Sex' and 'Embarked' columns. Make sure to drop the original columns after encoding."
      ],
      "id": "ax-Io0aBlMW5"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Oc-7mnsLlMW5"
      },
      "outputs": [],
      "source": [
        "# --- ENTER YOUR CODE HERE ---\n",
        "# 1. Use get_dummies to create new columns for 'Sex' and 'Embarked'\n",
        "# Set `drop_first=True` to avoid multicollinearity (a statistical issue), which drops one of the new columns (e.g., just having `Sex_male` is enough to know if someone is female).\n",
        "# encoded_df = pd.get_dummies(df, columns=[... , ...], drop_first=True)\n",
        "# 2. Display the first few rows of the new DataFrame to see the new columns\n",
        "# print(encoded_df.head())"
      ],
      "id": "Oc-7mnsLlMW5"
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "print(encoded_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HRbg_Zk4s6I",
        "outputId": "60d20d26-d939-4d01-8984-c5ca2d33eded"
      },
      "id": "1HRbg_Zk4s6I",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name   Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris  22.0      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n",
            "2                             Heikkinen, Miss. Laina  26.0      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n",
            "4                           Allen, Mr. William Henry  35.0      0      0   \n",
            "\n",
            "             Ticket     Fare Cabin  Sex_male  Embarked_Q  Embarked_S  \n",
            "0         A/5 21171   7.2500   NaN      True       False        True  \n",
            "1          PC 17599  71.2833   C85     False       False       False  \n",
            "2  STON/O2. 3101282   7.9250   NaN     False       False        True  \n",
            "3            113803  53.1000  C123     False       False        True  \n",
            "4            373450   8.0500   NaN      True       False        True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6_6rN5klMW6"
      },
      "source": [
        "## Part 4: Feature Scaling\n",
        "\n",
        "**Concept:** Many models are sensitive to the scale of the features. For example, `Age` (from 0-80) and `Fare` (from 0-512) are on very different scales. This can cause the model to incorrectly believe that `Fare` is a more important feature simply because its values are larger.\n",
        "\n",
        "**Feature Scaling** solves this by putting all features on a similar scale. A common method is **Standardization** (`StandardScaler` in scikit-learn), which rescales the data to have a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "**Important:** You only scale your numerical features, not your target variable or your newly encoded categorical columns."
      ],
      "id": "j6_6rN5klMW6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c71FP1_ylMW6"
      },
      "source": [
        "### Task 3: Scale the 'Age' and 'Fare' Columns\n",
        "\n",
        "**Your Task:** Use `StandardScaler` from `sklearn.preprocessing` to scale the 'Age' and 'Fare' columns."
      ],
      "id": "c71FP1_ylMW6"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n1FPJDKklMW6"
      },
      "outputs": [],
      "source": [
        "# --- ENTER YOUR CODE HERE ---\n",
        "# 1. Create an instance of the StandardScaler# scaler = ...\n",
        "# 2. Select the columns to scale\n",
        "# columns_to_scale = ['Age', 'Fare']\n",
        "# 3. Fit the scaler to the data and transform it\n",
        "# Note: We are using the `encoded_df` from the previous step if you created it.\n",
        "# encoded_df[columns_to_scale] = scaler.fit_transform(encoded_df[columns_to_scale])\n",
        "# 4. Display the first few rows to see the scaled data\n",
        "# print(encoded_df.head())"
      ],
      "id": "n1FPJDKklMW6"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "columns_to_scale = ['Age', 'Fare']\n",
        "scaler = StandardScaler()\n",
        "encoded_df[columns_to_scale] = scaler.fit_transform(encoded_df[columns_to_scale])\n",
        "print(encoded_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAPe8BNf5OTU",
        "outputId": "1802e87d-8ced-45a0-abdf-fca9626ee13e"
      },
      "id": "rAPe8BNf5OTU",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name       Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris -0.565736      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  0.663861      1      0   \n",
            "2                             Heikkinen, Miss. Laina -0.258337      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  0.433312      1      0   \n",
            "4                           Allen, Mr. William Henry  0.433312      0      0   \n",
            "\n",
            "             Ticket      Fare Cabin  Sex_male  Embarked_Q  Embarked_S  \n",
            "0         A/5 21171 -0.502445   NaN      True       False        True  \n",
            "1          PC 17599  0.786845   C85     False       False       False  \n",
            "2  STON/O2. 3101282 -0.488854   NaN     False       False        True  \n",
            "3            113803  0.420730  C123     False       False        True  \n",
            "4            373450 -0.486337   NaN      True       False        True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXtJZatxlMW6"
      },
      "source": [
        "## üìù Knowledge Check\n",
        "\n",
        "**Instructions:** Answer the following questions in this markdown cell.\n",
        "\n",
        "**[ENTER YOUR ANSWERS HERE]**\n",
        "\n",
        "1.  **Why is it often better to impute missing values with the median instead of the mean?**\n",
        "\n",
        "If the data is skewed or has outliers, mean would not provide the true middle.\n",
        "\n",
        "2.  **Explain in your own words what One-Hot Encoding does and why it is necessary.**\n",
        "\n",
        "One-Hot Encoding helps to encode categorical data into numerical by assigning them a value 0 or 1, True or False and such.\n",
        "\n",
        "3.  **Would you need to apply Feature Scaling to a Decision Tree model?** Why or why not? (Hint: Think about how a Decision Tree makes its splits).\n",
        "\n",
        "No, Feature Scaling is not important for Decision Tree model. Decision Trees can handle both numerical and categorical data and they split based on feature values not scale."
      ],
      "id": "LXtJZatxlMW6"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}